dataset:stas/openwebtext-10k

Perplexity======================================
For model: /kaggle/input/pretraning-mdl/GPT_512_100_2_percent.pth
Dataset Perplexity: 14756.8896484375

For model: /kaggle/input/pretraning-mdl/GPT_512_100_percent.pth
Dataset Perplexity: 10250.2060546875

For model: /kaggle/input/pretraning-mdl/GPT_512_50_2_percent.pth
Dataset Perplexity: 14575.63671875

For model: /kaggle/input/pretraning-mdl/GPT_Alpaca_512_100_percent.pth
Dataset Perplexity: 13382.7822265625

📌 Model: /kaggle/input/pretraning-another-2-mdl/GPT_Base_512_100_percent.pth
📊 Dataset Perplexity: 7140.8330078125


Loading model: /kaggle/input/pretraning-another-2-mdl/GPT_Base_512_50_percent.pth
Processing Batches: 100%|██████████| 625/625 [02:16<00:00,  4.58batch/s]
📌 Model: /kaggle/input/pretraning-another-2-mdl/GPT_Base_512_50_percent.pth
📊 Dataset Perplexity: 13931.294921875


======
5000条 都是1.3左右
dataset = load_dataset("bookcorpus", split="train", streaming=True, trust_remote_code=True)


📌 Model: /kaggle/input/pretraning-mdl/GPT_512_100_2_percent.pth
📊 Dataset Perplexity: 1.3610812425613403


Loading model: /kaggle/input/pretraning-mdl/GPT_512_100_percent.pth
Processing Batches: 100%|██████████| 313/313 [01:43<00:00,  3.02batch/s]
📌 Model: /kaggle/input/pretraning-mdl/GPT_512_100_percent.pth
📊 Dataset Perplexity: 1.3653234243392944


Loading model: /kaggle/input/pretraning-mdl/GPT_512_50_2_percent.pth
Processing Batches: 100%|██████████| 313/313 [01:43<00:00,  3.03batch/s]
📌 Model: /kaggle/input/pretraning-mdl/GPT_512_50_2_percent.pth
📊 Dataset Perplexity: 1.3439234495162964


Loading model: /kaggle/input/pretraning-mdl/GPT_Alpaca_512_100_percent.pth
Processing Batches: 100%|██████████| 313/313 [01:43<00:00,  3.03batch/s]
📌 Model: /kaggle/input/pretraning-mdl/GPT_Alpaca_512_100_percent.pth
📊 Dataset Perplexity: 1.3431512117385864

📌 Model: /kaggle/input/pretraning-another-2-mdl/GPT_Base_512_100_percent.pth
📊 Dataset Perplexity: 1.3320097923278809


Loading model: /kaggle/input/pretraning-another-2-mdl/GPT_Base_512_50_percent.pth
Processing Batches: 100%|██████████| 313/313 [01:08<00:00,  4.56batch/s]
📌 Model: /kaggle/input/pretraning-another-2-mdl/GPT_Base_512_50_percent.pth
📊 Dataset Perplexity: 1.321999073028564



================
dataset = load_dataset("FreedomIntelligence/medical-o1-reasoning-SFT", "en",split="train")


Model: /kaggle/input/pretraning-mdl/GPT_512_100_2_percent.pth
📊 Dataset Perplexity: 4.486678600311279


Loading model: /kaggle/input/pretraning-mdl/GPT_512_100_percent.pth
Processing Batches: 100%|██████████| 1586/1586 [08:59<00:00,  2.94batch/s]
📌 Model: /kaggle/input/pretraning-mdl/GPT_512_100_percent.pth
📊 Dataset Perplexity: 4.319518089294434


Loading model: /kaggle/input/pretraning-mdl/GPT_512_50_2_percent.pth
Processing Batches: 100%|██████████| 1586/1586 [08:59<00:00,  2.94batch/s]
📌 Model: /kaggle/input/pretraning-mdl/GPT_512_50_2_percent.pth
📊 Dataset Perplexity: 4.4268412590026855


Loading model: /kaggle/input/pretraning-mdl/GPT_Alpaca_512_100_percent.pth
Processing Batches: 100%|██████████| 1586/1586 [08:59<00:00,  2.94batch/s]
📌 Model: /kaggle/input/pretraning-mdl/GPT_Alpaca_512_100_percent.pth
📊 Dataset Perplexity: 4.788588523864746


📌 Model: /kaggle/input/pretraning-another-2-mdl/GPT_Base_512_100_percent.pth
📊 Dataset Perplexity: 4.13590669631958


Loading model: /kaggle/input/pretraning-another-2-mdl/GPT_Base_512_50_percent.pth
Processing Batches: 100%|██████████| 1586/1586 [05:45<00:00,  4.59batch/s]
📌 Model: /kaggle/input/pretraning-another-2-mdl/GPT_Base_512_50_percent.pth
📊 Dataset Perplexity: 4.257315635681152





Q A============================
GPT_512_50_2_percent.pth
Final Dataset Average Probability: 0.008644508

GPT_512_100_2_percent.pth
Final Dataset Average Probability: 0.007131684

GPT_512_100_percent.pth
Final Dataset Average Probability: 0.007239155

GPT_Alpaca_512_100_percent.pth
Final Dataset Average Probability: 0.019944078

GPT_Base_512_100_percent.pth
Final Dataset Average Probability: 0.006626897

GPT_Base_512_50_percent.pth
Final Dataset Average Probability: 0.004722948